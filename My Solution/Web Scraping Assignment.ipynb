{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTAwWJ5Qlmwk"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1Krpv420Trw6HQbArLSzrbYcpBz-9wgxw\" width=300/>\n",
    "\n",
    "# Data Engineering\n",
    "## Assignment 1: Webscraping wikipedia's Billboard pages\n",
    "\n",
    "**Alok K Pandey**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The Billboard Hot 100 is a chart that ranks the best-performing singles of the United States. Its data, published by Billboard magazine and compiled by Nielsen SoundScan, is based collectively on each single's weekly physical and digital sales, as well as airplay and streaming. At the end of a year, Billboard will publish an annual list of the 100 most successful songs throughout that year on the Hot 100 chart based on the information.\n",
    "    \n",
    ">> Check out Hot 100 single of 2022: https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYXK8VrcW9Mg"
   },
   "source": [
    "## Instructions <a class=\"anchor\" id=\"instructions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbPCzlmxXh2w"
   },
   "source": [
    "<hr style=\"height:2pt\">\n",
    "\n",
    "\n",
    "# Task 1: Constructing a year-song dataframe\n",
    "\n",
    "**Question 1:** Scrape and Parse Wikipedia for Billboard's Top 100 songs starting from 1992 to 2022.\n",
    "\n",
    "**1.1** Scrape Wikipedia's Billboard pages from 1992 to 2022.\n",
    "\n",
    "<details>\n",
    "\n",
    "- Use python's `requests` module to obtain (GET) the web pages at http://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1992, http://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1993 till http://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_2022.\n",
    "\n",
    "- Store the text from your `requests` in a dictionary called `yearstext`. \n",
    "This dictionary should have as its keys the years (as integers from 1992 to 2022), and as values corresponding to these keys the text of the page being fetched.\n",
    "\n",
    "*Hint:* Put your requests.get() in a `for` loop and use the `time.sleep` function to wait one second between requests, you do not want Wikipedia to think you are a marauding bot attempting to mount a denial-of-service attack.\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "**1.2** Parse the HTML retrieved to extract ranking, song and artist information. \n",
    "\n",
    "  **Note:** Here are some other issues that you will need to take care of while parsing:\n",
    "\n",
    "<details>\n",
    "    \n",
    "    i. The example shown above has several artists for a single song. In this case, the `band_singer` and `url` would be a list of items.\n",
    "\n",
    "    ii. Some singles might even have multiple songs because of the way the industry works:\n",
    "    ```\n",
    "    {'ranking': 98,\n",
    "    'song': [\"You're Makin' Me High\", 'Let It Flow (song)'],\n",
    "    'songurl': ['/wiki/You%27re_Makin%27_Me_High', '/wiki/Let_It_Flow_(song)'],\n",
    "    'titletext': '\"You\\'re Makin\\' Me High\" / \"Let It Flow\"',\n",
    "    'band_singer': ['Toni Braxton'],\n",
    "    'url': ['/wiki/Toni_Braxton']}\n",
    "    ```\n",
    "    (See 1997 for an example)\n",
    "\n",
    "    iii. Some songs don't have a URL. In this case, assume there is one song in the single, set `songurl` to [`None`] and the song name to the contents of the table cell with the quotes stripped:\n",
    "    ```\n",
    "    {'ranking': 45,\n",
    "      'song': ['Say It'],\n",
    "      'songurl': [None],\n",
    "      'titletext': '\"Say It\"',\n",
    "      'band_singer': ['Voices of Theory'],\n",
    "      'url': ['/wiki/Voices_of_Theory']}\n",
    "    ```\n",
    "    (See 1998 for an example)\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1653658404318,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "deZ11vb4lm3e",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# libraries to get you started\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "044UilQrsU_x"
   },
   "source": [
    "* Hint: Save the obtained dictionary as a json file so you do not need to run it over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully for 1992\n",
      "Data fetched successfully for 1993\n",
      "Data fetched successfully for 1994\n",
      "Data fetched successfully for 1995\n",
      "Data fetched successfully for 1996\n",
      "Data fetched successfully for 1997\n",
      "Data fetched successfully for 1998\n",
      "Data fetched successfully for 1999\n",
      "Data fetched successfully for 2000\n",
      "Data fetched successfully for 2001\n",
      "Data fetched successfully for 2002\n",
      "Data fetched successfully for 2003\n",
      "Data fetched successfully for 2004\n",
      "Data fetched successfully for 2005\n",
      "Data fetched successfully for 2006\n",
      "Data fetched successfully for 2007\n",
      "Data fetched successfully for 2008\n",
      "Data fetched successfully for 2009\n",
      "Data fetched successfully for 2010\n",
      "Data fetched successfully for 2011\n",
      "Data fetched successfully for 2012\n",
      "Data fetched successfully for 2013\n",
      "Data fetched successfully for 2014\n",
      "Data fetched successfully for 2015\n",
      "Data fetched successfully for 2016\n",
      "Data fetched successfully for 2017\n",
      "Data fetched successfully for 2018\n",
      "Data fetched successfully for 2019\n",
      "Data fetched successfully for 2020\n",
      "Data fetched successfully for 2021\n",
      "Data fetched successfully for 2022\n",
      "Data saved as JSON successfully. Name: parsed_data.json\n"
     ]
    }
   ],
   "source": [
    "# Start your code here\n",
    "#Code for 1.1\n",
    "import time\n",
    "\n",
    "# This dict will store the retrieved web page content from the URLs for each year. Will be converted to Json later\n",
    "scraped_data_yearwise = {}\n",
    "for year in range(1992, 2023):\n",
    "    URL = f\"http://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_{year}\"\n",
    "    \n",
    "    response = requests.get(URL)\n",
    "    # status_code = 200 is for when request is successful. helps to handle errors in the future.\n",
    "    if response.status_code == 200:\n",
    "        scraped_data_yearwise[year] = response.text\n",
    "        print(f\"Data fetched successfully for {year}\")\n",
    "    else:\n",
    "        # Handling other status codes\n",
    "        print(f\"Failed to fetch url data. Status code: {response.status_code}\")\n",
    "    # Sleep for one second between requests to avoid rate limits\n",
    "    time.sleep(1)\n",
    "\n",
    "#Code for 1.2\n",
    "# this list will contain extracted specific elements from the HTML content.\n",
    "parsed_data = []\n",
    "\n",
    "# Loop through each year in 'yearstext'\n",
    "for year, page_text in scraped_data_yearwise.items():\n",
    "    #BeautifulSoup is being used to parse current year's HTML content to object\n",
    "    content_current_year = BeautifulSoup(page_text, 'html.parser')\n",
    "    \n",
    "    # Find the table containing the song information\n",
    "    table = content_current_year.find('table', {'class': 'wikitable'})\n",
    "\n",
    "    # Extract rows from the table\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    # Loop through each row (skipping the header row)\n",
    "    for row in rows[1:]:\n",
    "        # Get the ranking, song title, and artist(s)\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        if len(cells) >= 3:\n",
    "            ranking = int(cells[0].text.strip())\n",
    "            title = cells[1].text.strip()\n",
    "            artist_text = cells[2].text.strip()\n",
    "\n",
    "            # Handle multiple songs and artists\n",
    "            song = title.strip('\"').split(\" / \")\n",
    "            artist = artist_text.split(\", \")\n",
    "\n",
    "            # Extract URLs for songs and artists\n",
    "            song_urls = [cell.find('a')['href'] if cell.find('a') else None for cell in row.find_all('td')[1:]]\n",
    "            artist_urls = [cell.find('a')['href'] if cell.find('a') else None for cell in row.find_all('td')[2:]]\n",
    "\n",
    "            # Create a dictionary with the extracted information\n",
    "            song_info = {\n",
    "                'year': year,\n",
    "                'ranking': ranking,\n",
    "                'song': song,\n",
    "                'songurl': song_urls,\n",
    "                'band_singer': artist,\n",
    "                'url': artist_urls\n",
    "            }\n",
    "            \n",
    "            parsed_data.append(song_info)\n",
    "\n",
    "#saving to json from dict\n",
    "json_data = json.dumps(parsed_data, indent=4)  # Convert with indentation for readability\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"parsed_data.json\", \"w\") as json_file:\n",
    "    json.dump(parsed_data, json_file, indent=4)  # Write to file with indentation\n",
    "print(\"Data saved as JSON successfully. Name: parsed_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kd_0dzuslm7B"
   },
   "source": [
    "<hr style=\"height:2pt\">\n",
    "\n",
    "**Question 2:** Construct a DataFrame from parsed data\n",
    "\n",
    "**2.1** Construct a dataframe from the dictionary `yearinfo`.\n",
    "\n",
    "<details>\n",
    "    \n",
    "- Construct a dataframe from the dictionary created in the previous section `yearinfo`. Name this dataframe `billboardtop`.<br><br>\n",
    "  Keep in mind, in the data structure we have so far, a given key can have a list of values with multiple entries. Also, our data is grouped by year. So we need a way to flatten this data into a format that will create a useful DataFrame. \n",
    "  Your final dataframe `billboardtop` should look something like this:\n",
    "\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1adDiuSmHXR7B7YO2ZNT_OJ9QejUyuJAC\" width=1500/>\n",
    "\n",
    "- Ensure that all lists in your dictionary are in different rows. <br>\n",
    "  For example, a single containing two artists should be two different rows:\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1hxGXmP20vJ5i1N7WDg_pZBYly7gX2Gz0\" width=1500/>\n",
    "\n",
    "  A single containing two titles (1997, Rank 98) should be two different rows:\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1nRrDQOixcH4HfahfA9YF7R7brm_OyD7d\" width=1500/>\n",
    "\n",
    "</details>\n",
    "\n",
    "**2.2** Check your dataframes data types and convert them to the correct data types if needed.\n",
    "\n",
    "- Check dataframe data types using ```dtypes```.\n",
    "- Convert them to the correct data types if needed using the ```astype()``` function.\n",
    "\n",
    "**2.3** Store this dataframe in ADLS so that you can use it for tasks ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hint: Use pickle to save you data, it retains your given datatypes and few other metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'billboardtop' constructed and saved as 'billboardtop.pickle'.\n",
      "   year  ranking             song                                   songurl  \\\n",
      "0  1992        1  End of the Road  /wiki/End_of_the_Road_(Boyz_II_Men_song)   \n",
      "1  1992        1  End of the Road                         /wiki/Boyz_II_Men   \n",
      "2  1992        2    Baby Got Back                       /wiki/Baby_Got_Back   \n",
      "3  1992        2    Baby Got Back                       /wiki/Sir_Mix-a-Lot   \n",
      "4  1992        3             Jump              /wiki/Jump_(Kris_Kross_song)   \n",
      "\n",
      "     band_singer                  url  \n",
      "0    Boyz II Men    /wiki/Boyz_II_Men  \n",
      "1    Boyz II Men    /wiki/Boyz_II_Men  \n",
      "2  Sir Mix-a-Lot  /wiki/Sir_Mix-a-Lot  \n",
      "3  Sir Mix-a-Lot  /wiki/Sir_Mix-a-Lot  \n",
      "4     Kris Kross     /wiki/Kris_Kross  \n"
     ]
    }
   ],
   "source": [
    "# Start your code here\n",
    "import pickle\n",
    "\n",
    "# Loading JSON data: parsed_data.json\n",
    "with open(\"parsed_data.json\", \"r\") as json_file:\n",
    "    parsed_data = json.load(json_file)\n",
    "\n",
    "# Create a DataFrame from the parsed data\n",
    "billboardtop = pd.DataFrame(parsed_data)\n",
    "\n",
    "# Ensure that lists within the dictionary are in different rows (flattening)\n",
    "billboardtop = billboardtop.explode(\"song\")  # Splitting the 'song' list into separate rows\n",
    "billboardtop = billboardtop.explode(\"songurl\")  # Splitting 'songurl' list into separate rows\n",
    "billboardtop = billboardtop.explode(\"band_singer\")  # Splitting 'band_singer' into separate rows\n",
    "billboardtop = billboardtop.explode(\"url\")  # Splitting 'url' into separate rows\n",
    "\n",
    "# Convert data types if needed\n",
    "billboardtop[\"ranking\"] = billboardtop[\"ranking\"].astype(int)  # Ensure 'ranking' is int\n",
    "billboardtop[\"year\"] = billboardtop[\"year\"].astype(int)  # Ensure 'year' is int\n",
    "\n",
    "# Reset the index to ensure proper DataFrame structure\n",
    "billboardtop.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the DataFrame as a pickle file for storage\n",
    "with open(\"billboardtop.pickle\", \"wb\") as pickle_file:\n",
    "    pickle.dump(billboardtop, pickle_file)\n",
    "\n",
    "print(\"DataFrame 'billboardtop' constructed and saved as 'billboardtop.pickle'.\")\n",
    "print(billboardtop.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmtbYTjl8rR0"
   },
   "source": [
    "# Part B: Constructing a year-song-singer dataframe\n",
    "\n",
    "Now, we need to fetch information about the singers or bands for all the songs we have in the `billboardtop` dataframe.\n",
    "\n",
    "**Question 1:** Scrape and Parse Wikipedia for information about Artists and Bands\n",
    "\n",
    "**1.1** Scrape the artist's Wikipedia webpages.\n",
    "\n",
    "<details>\n",
    "\n",
    "Since we have hundreds of artists webpages to scrape, we have created a function which implements caching in order to speed up this process.\n",
    "\n",
    "The cache object urlcache that will avoid redundant HTTP requests (e.g. an artist might have multiple singles on a single year, or be on the list over a span of years). **Remember that this function is designed to be used in a loop over years, and then a loop over songs per year.** Since network requests are relatively slow, if we have already requested for a singer or band's wikipedia page, caching the results is a smart thing to do.\n",
    "\n",
    "Notice that we have wrapped the call in an exception block. If the request gets an HTTP code different from 200, the cells for that URL will have a value of 1; and if the request completely fails (e.g. no network connection) the cell will have a value of 2. This will allow you to analyse the failed requests.\n",
    "\n",
    "</details>\n",
    "\n",
    "**1.2** Parse the HTML retrieved to extract genre of the artist, date of birth, years active and other artist information.\n",
    "\n",
    "<details>\n",
    "\n",
    "- Write a function `singer_band_info(url, page_text)` that returns a dictionary. \n",
    "\n",
    "  Here `url` should be the the url corresponding to the singer's Wikipedia page (same as the previous dataframe `billboardtop`), and page_text should be the HTML text for the corresponding artist's webpage. This function should return a dictionary which contains the following information:\n",
    "\n",
    "  1. The genres of the band or singer. These genres should be urls, to ensure their uniqueness. Create a list, `genres`, of these urls. If there are no genres, use `['NA']`.\n",
    "\n",
    "  2. If the page has the text \"Born\", extract the element with the class `.bday`. If there is no \"Born\", store `False`. Store either of these into the variable `born`. \n",
    "\n",
    "  3. If the text \"Years active\" is found, but there is no birthday, assume a band. Store the years active into the variable `ya`, or `False` if the text is not found. \n",
    "\n",
    "  The dictionary returned should be of the form:\n",
    "  ```\n",
    "  { 'url': '/wiki/Boyz_II_Men', \n",
    "  'genres': ['/wiki/Contemporary_R%26B_music', '/wiki/Soul_music', '/wiki/New_jack_swing'], \n",
    "  'born': None, \n",
    "  'ya': '1987–present'}\n",
    "  ```\n",
    "- Once the above function is created, generate a list `singer_band_info_list` to store the information extracted above. `singer_band_info_list` should be a list of the dictionaries that the function `singer_band_info` returns. The list should look something like this:\n",
    "```\n",
    "  'genres': ['/wiki/Contemporary_R%26B_music',\n",
    "   '/wiki/Soul_music',\n",
    "   '/wiki/New_jack_swing'],\n",
    "  'url': '/wiki/Boyz_II_Men',\n",
    "  'ya': '1987–present'},\n",
    " {'born': None,\n",
    "  'genres': ['/wiki/Pop_music',\n",
    "   '/wiki/Electronica_music',\n",
    "   '/wiki/Dance_music',\n",
    "   '/wiki/Rave_music',\n",
    "   '/wiki/House_music'],\n",
    "  'url': '/wiki/KWS_(band)',\n",
    "  'ya': '1991–1994'},\n",
    " ... and so on]\n",
    "  ```\n",
    "<br>\n",
    "\n",
    "  **Note:** Wikipedia has changed it's format along the years! So observing one artist's webpage and building your function based on it will probably give you tons of errors. Here are a few issues to remember while parsing:\n",
    "\n",
    "    1. There are several artists that take a sabbatical between their active years (https://en.wikipedia.org/wiki/Tony!_Toni!_Ton%C3%A9!). To get the right data, write a function to calculate the longest period of time they were active and consider that as your variable `years active`. In the example give, this would be 2003–present.\n",
    "    2. Birthday's are given in different formats for different pages. For example - https://en.wikipedia.org/wiki/Sir_Mix-a-Lot and https://en.wikipedia.org/wiki/Ed_Sheeran have different formats. To ensure that you get the right day, look for the 'span' tag with a 'bday' tag and ensure that there are no paranthesis around the extracted text.\n",
    "    3. Year's active are also given in different formats. For example - https://en.wikipedia.org/wiki/Boyz_II_Men and https://en.wikipedia.org/wiki/Ed_Sheeran are different. You could use regex (\"[0-9]{4}[–][0-9]{4}\" and \"[0-9]{4}[–][0-9]{4}\") to ensure you are getting the right years.\n",
    "\n",
    "  Definitely do look at your outputs as you are parsing as it can identify several edge cases you have not considered in your code.\n",
    "\n",
    "</details>\n",
    "\n",
    "**Question 2:** Construct a DataFrame from parsed data\n",
    "\n",
    "**2.1** Construct a dataframe from the list `singer_band_info_list` and convert them to the correct data types if needed.\n",
    "\n",
    "<details>\n",
    "\n",
    "- Construct a dataframe from the list created in the previous section yearinfo. Name this dataframe `singerbandinfo`.\n",
    "\n",
    "  Your dataframe `singerbandinfo` should look something like this:\n",
    "\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1LZh_J-LsB2p9UW7lCJaSbPNMTH-Bv61p\" width=1500/> \n",
    "\n",
    "- Check dataframe data types using dtypes.\n",
    "- Convert them to the correct data types if needed using the astype() function.\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "**2.2** Merge `billboardtop` and `singerbandinfo` to create one dataframe.\n",
    "\n",
    "<details>\n",
    "\n",
    "- Merge the artist/song data frames into one large dataframe named `finaldf` on url. Your  dataframe should look something like this:\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1JMoV2gvIpIQ4tDGwidT7eAGKGusF8V0Z\" width=1500/> \n",
    "\n",
    "  Note that this has an effect of imputing to a song all the genres that the artist is active in. We know that this is not true, but it is the simplest assumption we can make, and is probably good for most artists.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kB54u81xJk-"
   },
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuL6xVq1xN47"
   },
   "source": [
    "#### Question 1: Scrape and Parse Wikipedia for information about Artists and Bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byvQaqnFxcHZ"
   },
   "source": [
    "**1.1** Scrape the artist's Wikipedia webpages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hint: Before you apply uour function to the dataframe, sort `billboardtop` by year. This will ensure that we will hit the cache most as singers who show up repeatedly in the rankings will have their information already pulled.\n",
    "\n",
    "This is optional from the perspective to optimization, you can choose to ignore it but then you will have higher run time at your end and you will end up writing more code to maintain data sanity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1653658771530,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "xLIr5RLOlm8C",
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "urlcache={}\n",
    "def get_page(url):\n",
    "    if (url not in urlcache) or (urlcache[url]==1) or (urlcache[url]==2):\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            r = requests.get(\"http://en.wikipedia.org%s\" % url)\n",
    "            if r.status_code == 200:\n",
    "                urlcache[url] = r.text\n",
    "            else:\n",
    "                urlcache[url] = 1\n",
    "        except:\n",
    "            urlcache[url] = 2\n",
    "    return urlcache[url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1765677,
     "status": "ok",
     "timestamp": 1653660540815,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "jGHEg1IDlm8O",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "df1ec7d5-b8fa-4308-9db1-8eba93d42fe4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here I am populating the url cache\n",
    "# Note that this function will take around 20 minutes to run as we are requesting for several pages\n",
    "# This function is designed to be run again and again: it just tries to make sure that there are no unresolved pages left. \n",
    "billboardtop[\"url\"].apply(get_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1653660540816,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "vtH5ch-Jlm8X",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "380967e1-4187-4b65-d5ea-7b7372f890f9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make sure that there are no unresolved pages\n",
    "# The sum below should be 0, and the boolean True. If that is not the case, run the above cell again until you get a sum of 0 and a boolean True\n",
    "print (np.sum([(urlcache[k]==1) or (urlcache[k]==2) and isinstance(k,str) for k in urlcache]))\n",
    "print (\"Did we get all the URLs?\",len(billboardtop.url.unique())==len(urlcache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2639,
     "status": "ok",
     "timestamp": 1653660543451,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "u-g3mOWrlm8c",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Saving the `urlcache` and removin the old object. \n",
    "keys_values = urlcache.items()\n",
    "urlcache = {str(key): str(value) for key, value in keys_values}\n",
    "with open(\"artistinfo.json\",\"w\") as fd:\n",
    "    json.dump(urlcache, fd)\n",
    "del urlcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3867,
     "status": "ok",
     "timestamp": 1653660547316,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "ctcBqdEPlm8f",
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading artist info\n",
    "with open(\"artistinfo.json\") as json_file:\n",
    "    urlcache = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1653660547317,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "aaflaMIF6N91",
    "outputId": "e5afb222-6434-4022-ee14-f3183676bd6d"
   },
   "outputs": [],
   "source": [
    "len(urlcache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_G84LnUlm8p"
   },
   "source": [
    "**1.2** Parse the HTML retrieved to extract genre of the artist, date of birth, years active and other artist information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wepOCDnV2H3p"
   },
   "source": [
    "Before parsing, it is important to note that Wikipedia has defined the same genre in a few different ways. Your parsing code will pick these up as different and new as they all differ with the alphabet case or an underscore instead of a hyphen.\n",
    "\n",
    "I am adding potential duplicates list to make the task a little easier so that the above mentioned issue does not create duplicate data under same categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1653660547317,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "QTSJHvJF3pxu"
   },
   "outputs": [],
   "source": [
    "genres_duplicates= {'/wiki/Adult_Contemporary_music':'/wiki/Adult_contemporary',\n",
    " '/wiki/Adult_contemporary_music':'/wiki/Adult_contemporary',\n",
    "'/wiki/Afrobeat':'/wiki/Afrobeats',\n",
    "'/wiki/Alternative_rock':'/wiki/Alternative_Rock',\n",
    "'/wiki/Avant-garde':'/wiki/Avant-garde_music',\n",
    "'/wiki/Blues':'/wiki/Blues_music',\n",
    "'/wiki/Comedy_hip-hop':'/wiki/Comedy_hip_hop',\n",
    "'/wiki/Contemporary_R%26B':'/wiki/Contemporary_R%26B_music',\n",
    "'/wiki/Contemporary_folk':'/wiki/Contemporary_folk_music',\n",
    "'/wiki/Country_Folk':'/wiki/Country_folk',\n",
    "'/wiki/Dance_pop':'/wiki/Dance-pop',\n",
    "'/wiki/East_Coast_hip_hop':'/wiki/East_coast_hip_hop',\n",
    "'/wiki/Electronic_Dance_Music':'/wiki/Electronic_dance_music',\n",
    "'/wiki/Electronica':'/wiki/Electronica_music',\n",
    "'/wiki/Emo':'/wiki/Emo_music',\n",
    "'/wiki/Electropop':'/wiki/Electro-pop',\n",
    "'/wiki/Folk-pop':'/wiki/Folk_pop',\n",
    "'/wiki/Funk':'/wiki/Funk_music',\n",
    "'/wiki/Grime_(music_genre)':'/wiki/Grime_music',\n",
    "'/wiki/Gangsta_Rap':'/wiki/Gangsta_rap',\n",
    "'/wiki/Hip_Hop_music': '/wiki/Hip_hop','/wiki/Hip_hop_music':'/wiki/Hip_hop',\n",
    "'/wiki/Hyphy':'/wiki/Hyphy_music',\n",
    "'/wiki/Latin_music':'/wiki/Latin_music_(genre)',\n",
    "'/wiki/West_Coast_hip_hop':'/wiki/West_coast_hip_hop',\n",
    "'/wiki/Southern_Hip_Hop':'/wiki/Southern_hip_hop',\n",
    "'/wiki/Ska':'/wiki/Ska_music',\n",
    "'/wiki/Pop-rock':'/wiki/Pop_rock',\n",
    "'/wiki/Pop_Music':'/wiki/Pop_music',\n",
    "'/wiki/Nu_metal':'/wiki/Nu_metal_music',\n",
    "'/wiki/Hard_Rock':'/wiki/Hard_rock',\n",
    "'/wiki/Pop_Rock':'/wiki/Pop_rock',\n",
    "'/wiki/Post-Grunge':'/wiki/Post-grunge',\n",
    "'/wiki/SoundCloud_rap':'/wiki/Soundcloud_rap'}\n",
    "\n",
    "def genre_duplicates(genres):\n",
    "    for i in range(len(genres)):\n",
    "        if genres[i] in genres_duplicates.keys():\n",
    "            genres[i]=genres_duplicates[genres[i]]\n",
    "    return genres "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2.1** Define a function to calculate the longest active years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1653658444655,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "iCiUaa3t1mdM"
   },
   "outputs": [],
   "source": [
    "# Start your code here\n",
    "import re\n",
    "\n",
    "# Goal: to calculate longest active years from a list of active year strings\n",
    "def longest_active_years(active_years):\n",
    "    # Extract all the spans of years from the given active_years string(s)\n",
    "    spans = re.findall(r\"\\d{4}–\\d{4}\", active_years)\n",
    "\n",
    "    # If there are multiple spans, find the longest one\n",
    "    longest_span = None\n",
    "    longest_duration = 0\n",
    "    \n",
    "    for span in spans:\n",
    "        start_year, end_year = map(int, span.split('–'))\n",
    "        duration = end_year - start_year\n",
    "        \n",
    "        if duration > longest_duration:\n",
    "            longest_duration = duration\n",
    "            longest_span = span\n",
    "    \n",
    "    return longest_span\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C30IKrh_lm89"
   },
   "source": [
    "**1.2.2** Please write the function `singer_band_info` according to the following specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1653658444655,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "144RCE17lm9C",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "singer_band_info\n",
    "\n",
    "Inputs\n",
    "------\n",
    "url: the url\n",
    "page_text: the text associated with the url\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "A dictionary with the following data:\n",
    "    url: copy the input argument url into this value\n",
    "    genres: the genres that the band or singer works in\n",
    "    born: the artist's birthday\n",
    "    ya: years active variable\n",
    "\n",
    "Notes\n",
    "-----\n",
    "See description above. Also note that some of the genres urls might require a \n",
    "bit of care and special handling.\n",
    "\"\"\"\n",
    "# Start your code here\n",
    "\n",
    "def singer_band_info(url, page_text):\n",
    "    # Create a BeautifulSoup object to parse the HTML text\n",
    "    soup = BeautifulSoup(page_text, \"html.parser\")\n",
    "    \n",
    "    # Initialize the dictionary with the URL\n",
    "    info = {\n",
    "        \"url\": url,\n",
    "        \"genres\": [],\n",
    "        \"birth\": None,\n",
    "        \"years_active\": None\n",
    "    }\n",
    "    \n",
    "    # Extract genres\n",
    "    genres = []\n",
    "    genre_elements = soup.find_all(\"a\", href=re.compile(\"/wiki/\"))\n",
    "    for element in genre_elements:\n",
    "        href = element.get(\"href\", \"\")\n",
    "        if \"/wiki/Category:\" not in href:  # Avoid category pages\n",
    "            genres.append(href)\n",
    "    \n",
    "    # Clean up genres to handle duplicates or variations\n",
    "    info[\"genres\"] = list(set(genre_duplicates(genres)))\n",
    "    \n",
    "    # Extract the \"Born\" date\n",
    "    born_element = soup.find(\"span\", class_=\"bday\")\n",
    "    if born_element:\n",
    "        info[\"birth\"] = born_element.get_text()\n",
    "    else:\n",
    "        info[\"birth\"] = None  # Default if no \"Born\" date found\n",
    "    \n",
    "    # Extract the years active\n",
    "    active_text = soup.find(text=re.compile(\"Years active\"))\n",
    "    if active_text:\n",
    "        parent = active_text.parent\n",
    "        if parent:\n",
    "            # Use regex to find the span of years\n",
    "            year_match = re.search(r\"(\\d{4}–\\d{4}|\\d{4}–present)\", parent.text)\n",
    "            if year_match:\n",
    "                info[\"years_active\"] = year_match.group(0)\n",
    "            else:\n",
    "                info[\"years_active\"] = None\n",
    "    else:\n",
    "        info[\"years_active\"] = None\n",
    "    \n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r33k0Rv9lm9M"
   },
   "source": [
    "#### Question 2: Construct a DataFrame from parsed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFBbluyq_xUg"
   },
   "source": [
    "**2.1** Construct a dataframe from the list `singer_band_info_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1653658444656,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "mvihe4PIKBkv"
   },
   "outputs": [],
   "source": [
    "# Start your code here\n",
    "# list to store info about singers & bands\n",
    "singer_band_info_list = []\n",
    "\n",
    "for url in billboardtop['url']:\n",
    "    url_complete = f\"https://en.wikipedia.org{url}\" \n",
    "    response = requests.get(url_complete)\n",
    "\n",
    "    # If the request is successful, process the information\n",
    "    if response.status_code == 200:\n",
    "        page_text = response.text\n",
    "        # usage of singer_band_info function here:\n",
    "        get_info = singer_band_info(url_complete, page_text)\n",
    "        singer_band_info_list.append(get_info)\n",
    "    else:\n",
    "        # If not successful, use default values\n",
    "        singer_band_info_list.append({'url': url_complete, 'genres': ['NA'], 'born': None, 'years_active': None})\n",
    "\n",
    "print(singer_band_info_list.head())\n",
    "with open('singer_band_info_list.json', 'w') as file:\n",
    "    json.dump(singer_band_info_list, file)\n",
    "print(\"Dumping singer_band_info_list for uninterrupted usage later adn to get dataframe from it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipg0V9b5ILZ9"
   },
   "source": [
    "**2.2** Merge billboardtop and singerbandinfo to create one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1653658444656,
     "user": {
      "displayName": "Arya Mohan",
      "userId": "15606194433450766788"
     },
     "user_tz": -330
    },
    "id": "zXmWArJllm9h",
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start your code here\n",
    "# Construct the singerbandinfo DataFrame from the list of dictionaries\n",
    "singerbandinfo_df = pd.DataFrame(singer_band_info_list)\n",
    "\n",
    "# Merge the two dataframes on the 'url' column\n",
    "final_data = pd.merge(billboardtop, singerbandinfo_df, on='url', how='inner')\n",
    "\n",
    "# Display the merged dataframe to confirm the structure\n",
    "print(final_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mdmfw0ZIGlG5"
   },
   "source": [
    "# Part C: Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Question 1:** What has been the trajectory of various genres in the popular zeitgeist?<br>\n",
    "\n",
    "**1.1** What are the 30 most popular genres?<br>\n",
    "\n",
    "<details>\n",
    "\n",
    "1.1.1 Find the top 30 genres and plot a bar plot of these genres.<br>\n",
    "1.1.2 Feel free to plot any other visualizations that you can think of!<br>\n",
    "1.1.3 Calculate the mean of the dataframe and eliminate the first two columns (`year` and `ranking`) to get means of all the genre columns.<br>\n",
    "1.1.4 Sort it in ascending order and pick the top 30.<br>\n",
    "\n",
    "</details>\n",
    "\n",
    "**1.2** How has the popularity of these 30 genres changed with time?<br>\n",
    "\n",
    "<details>\n",
    "\n",
    "1.2.1 Create a subframe of the ranking and year for each genre.<br>\n",
    "1.2.2 Groupby() function to group by year to create a dataframe that contains the rankings of every song from that genre in a given year.<br>\n",
    "\n",
    "</details>\n",
    "\n",
    "**Question 2:** Who are the highest quality singers?<br>\n",
    "\n",
    "**2.1** Who are the most occurring artists in Billboard's Top 100 list?<br>\n",
    "\n",
    "<details>\n",
    "\n",
    "2.1.1 Count the number of times a singer appears in the top 100 over a certain time period. Consider an artist appearing twice in a year as two appearances.<br>\n",
    "\n",
    "2.1.2 Plot a bar chart of the artists who have occurred at least more than 15 times in the given time frame.<br>\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "**2.3**  What is the age at which singers achieve their top ranking?<br>\n",
    "\n",
    "<details>\n",
    "\n",
    "* Plot a histogram of the age at which artists reach their top ranking.<br>\n",
    "\n",
    "</details>\n",
    "\n",
    "**2.4** At what year since inception do bands reach their top rankings?<br>\n",
    "\n",
    "<details>\n",
    "\n",
    "* Make a similar calculation to plot a histogram of the years since inception at which bands reach their top ranking.<br>\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vP4btHmCGlHf"
   },
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your code here\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Given final_data (merged DataFrame from previous steps)\n",
    "\n",
    "# -- Question 1: Trajectory of Various Genres in the Popular Zeitgeist --\n",
    "\n",
    "# **1.1** Goal: to find the top 30 genres and plot a bar plot\n",
    "# Extracted all unique genres from 'genres' column and count their occurrences\n",
    "all_genres = []\n",
    "for genres in finaldf['genres']:\n",
    "    if genres:  # Make sure it's not empty\n",
    "        all_genres.extend(genres)\n",
    "\n",
    "# Create a Series with genre counts\n",
    "genre_counts = pd.Series(all_genres).value_counts()\n",
    "\n",
    "# Get the top 30 genres and plot a bar plot\n",
    "top_30_genres = genre_counts.head(30)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=top_30_genres.values, y=top_30_genres.index, orient='h')\n",
    "plt.title(\"Top 30 Most Popular Genres\")\n",
    "plt.xlabel(\"Number of Occurrences\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **1.2** How has the popularity of these 30 genres changed with time?\n",
    "\n",
    "# Create a dataframe to hold the ranking and year for each genre\n",
    "genre_years = pd.DataFrame()\n",
    "\n",
    "# Append rankings and years for each genre\n",
    "for genre in top_30_genres.index:\n",
    "    genre_years = pd.concat([genre_years, finaldf[['year', 'ranking']].loc[finaldf['genres'].apply(lambda g: genre in g)]])\n",
    "\n",
    "# Group by year and calculate the mean ranking for each genre\n",
    "genre_trends = genre_years.groupby('year').mean().sort_index()\n",
    "\n",
    "# Plot the trend of popularity for the top 30 genres over time\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(data=genre_trends, x='year', y='ranking')\n",
    "plt.title(\"Popularity Trend of Top 30 Genres Over Time\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Average Ranking\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Question 2: Who Are the Highest Quality Singers? --\n",
    "\n",
    "# **2.1** Who are the most occurring artists in Billboard's Top 100 list?\n",
    "# Count the number of times an artist appears in the top 100 over the given time period\n",
    "artist_occurrences = finaldf['artist'].value_counts()\n",
    "\n",
    "# Plot a bar chart of artists who have occurred at least 15 times in the given time frame\n",
    "min_occurrences = 15\n",
    "artists_above_threshold = artist_occurrences[artist_occurrences > min_occurrences]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=artists_above_threshold.values, y=artists_above_threshold.index, orient='h')\n",
    "plt.title(\"Artists with More Than 15 Occurrences in Billboard's Top 100\")\n",
    "plt.xlabel(\"Number of Occurrences\")\n",
    "plt.show()\n",
    "\n",
    "# 2.2 not given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **2.3** What is the age at which singers achieve their top ranking?\n",
    "# Extract the ages and plot a histogram\n",
    "finaldf['birth'] = pd.to_datetime(finaldf['birth'], errors='coerce')  # Convert 'birth' to datetime\n",
    "finaldf['age_at_top'] = finaldf['year'] - finaldf['birth'].dt.year  # Calculate age at top ranking\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.histplot(data=finaldf, x='age_at_top', kde=True)\n",
    "plt.title(\"Histogram of Age at Which Singers Achieve Their Top Ranking\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **2.4** At what year since inception do bands reach their top rankings?\n",
    "# Calculate years since inception and plot a histogram\n",
    "finaldf['inception'] = pd.to_datetime(finaldf['years_active'].apply(lambda ya: ya.split(\"–\")[0]), errors='coerce')\n",
    "finaldf['years_since_inception'] = finaldf['year'] - finaldf['inception'].dt.year  # Years since inception\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.histplot(data=finaldf, x='years_since_inception', kde=True)\n",
    "plt.title(\"Histogram of Years Since Inception When Bands Reach Their Top Rankings\")\n",
    "plt.xlabel(\"Years Since Inception\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Kd_0dzuslm7B",
    "QmtbYTjl8rR0",
    "r33k0Rv9lm9M"
   ],
   "name": "HW1_Solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
